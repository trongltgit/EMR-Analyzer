import os
import numpy as np
import tensorflow as tf
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
from PIL import Image
import py7zr
import logging

logging.basicConfig(level=logging.DEBUG, filename="server.log",
                    format="%(asctime)s - %(levelname)s - %(message)s")

app = Flask(__name__)
CORS(app)

# Config model
MODEL_DIR = "./models"
MODEL_PARTS = [
    os.path.join(MODEL_DIR, "best_weights_model.7z.001"),
    os.path.join(MODEL_DIR, "best_weights_model.7z.002"),
    os.path.join(MODEL_DIR, "best_weights_model.7z.003"),
    os.path.join(MODEL_DIR, "best_weights_model.7z.004")
]
MODEL_PATH_7Z = os.path.join(MODEL_DIR, "best_weights_model.7z")
MODEL_EXTRACTED_PATH = os.path.join(MODEL_DIR, "best_weights_model.keras")

def merge_model_parts():
    if not os.path.exists(MODEL_PATH_7Z):
        logging.info("üì¶ ƒêang gh√©p c√°c file .7z...")
        with open(MODEL_PATH_7Z, "wb") as output_file:
            for part in MODEL_PARTS:
                if not os.path.exists(part):
                    logging.error(f"File {part} kh√¥ng t·ªìn t·∫°i!")
                    raise FileNotFoundError(f"File {part} kh√¥ng t·ªìn t·∫°i!")
                with open(part, "rb") as part_file:
                    output_file.write(part_file.read())
        logging.info("‚úÖ Gh√©p file .7z th√†nh c√¥ng!")

def extract_model():
    if not os.path.exists(MODEL_EXTRACTED_PATH):
        logging.info("üì¶ ƒêang gi·∫£i n√©n model...")
        with py7zr.SevenZipFile(MODEL_PATH_7Z, mode='r') as archive:
            archive.extractall(MODEL_DIR)
        logging.info("‚úÖ Gi·∫£i n√©n th√†nh c√¥ng!")

model = None
def load_model():
    global model
    if model is None:
        try:
            merge_model_parts()
            extract_model()
            logging.info("üì¶ ƒêang t·∫£i model v√†o b·ªô nh·ªõ...")
            model = tf.keras.models.load_model(MODEL_EXTRACTED_PATH)
            logging.info("‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c load!")
        except Exception as e:
            logging.error(f"L·ªói khi t·∫£i model: {str(e)}")
            raise

# Preload model khi kh·ªüi ƒë·ªông server (n·∫øu c√≥ th·ªÉ)
with app.app_context():
    try:
        load_model()
        logging.info("‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c preload!")
    except Exception as e:
        logging.error(f"L·ªói preload model: {str(e)}")

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/dashboard')
def dashboard():
    return render_template('dashboard.html')

@app.route('/predict', methods=['POST'])
def predict():
    try:
        # N·∫øu model kh√¥ng ƒë∆∞·ª£c preload th√†nh c√¥ng, th·ª≠ t·∫£i l·∫°i
        if model is None:
            load_model()
            
        if 'image' not in request.files:
            logging.warning("Kh√¥ng c√≥ file ·∫£nh ƒë∆∞·ª£c g·ª≠i!")
            return jsonify({'error': 'Kh√¥ng c√≥ file ·∫£nh ƒë∆∞·ª£c g·ª≠i!'}), 400

        file = request.files['image']
        if file.filename == '':
            return jsonify({'error': 'T√™n file r·ªóng!'}), 400

        image = Image.open(file).convert('RGB')
        image = image.resize((224, 224))
        img_array = np.array(image) / 255.0
        img_array = np.expand_dims(img_array, axis=0)

        predictions = model.predict(img_array)
        logging.info(f"üìä K·∫øt qu·∫£ d·ª± ƒëo√°n: {predictions}")
        return jsonify({'predictions': predictions.tolist()})
    except Exception as e:
        logging.error(f"L·ªói trong route /predict: {str(e)}")
        return jsonify({'error': f'Internal Server Error: {str(e)}'}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
