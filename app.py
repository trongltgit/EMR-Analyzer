import os
import threading
import json
import numpy as np
import tensorflow as tf
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
from PIL import Image
import py7zr
import logging
from pathlib import Path
import cv2
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt
import urllib.request
from google.colab import drive
drive.mount('/content/drive')

# ƒê∆∞·ªùng d·∫´n ƒë·∫øn m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u tr·ªØ c√≥ ƒë·ªô ch√≠nh x√°c cao nh·∫•t tr√™n t·∫≠p ki·ªÉm th·ª≠
model_path = '/content/drive/MyDrive/efficientnet/efficientnet/best_weights_model.keras'
best_model = load_model(model_path)

logging.basicConfig(level=logging.DEBUG, filename="server.log",
                    format="%(asctime)s - %(levelname)s - %(message)s")

app = Flask(__name__)
CORS(app)

# Config model
MODEL_DIR = "./models"
MODEL_PARTS = [
    os.path.join(MODEL_DIR, "best_weights_model.7z.001"),
    os.path.join(MODEL_DIR, "best_weights_model.7z.002"),
    os.path.join(MODEL_DIR, "best_weights_model.7z.003"),
    os.path.join(MODEL_DIR, "best_weights_model.7z.004")
]
MODEL_PATH_7Z = os.path.join(MODEL_DIR, "best_weights_model.7z")
MODEL_EXTRACTED_PATH = os.path.join(MODEL_DIR, "best_weights_model.keras")

def merge_model_parts():
    if not os.path.exists(MODEL_PATH_7Z):
        logging.info("üì¶ ƒêang gh√©p c√°c file .7z...")
        with open(MODEL_PATH_7Z, "wb") as output_file:
            for part in MODEL_PARTS:
                if not os.path.exists(part):
                    logging.error(f"File {part} kh√¥ng t·ªìn t·∫°i!")
                    raise FileNotFoundError(f"File {part} kh√¥ng t·ªìn t·∫°i!")
                with open(part, "rb") as part_file:
                    output_file.write(part_file.read())
        logging.info("‚úÖ Gh√©p file .7z th√†nh c√¥ng!")

def extract_model():
    if not os.path.exists(MODEL_EXTRACTED_PATH):
        logging.info("üì¶ ƒêang gi·∫£i n√©n model...")
        with py7zr.SevenZipFile(MODEL_PATH_7Z, mode='r') as archive:
            archive.extractall(MODEL_DIR)
        logging.info("‚úÖ Gi·∫£i n√©n th√†nh c√¥ng!")

model = None
def load_model():
    global model
    if model is None:
        try:
            merge_model_parts()
            extract_model()
            logging.info("üì¶ ƒêang t·∫£i model v√†o b·ªô nh·ªõ...")
            model = tf.keras.models.load_model(MODEL_EXTRACTED_PATH)
            logging.info("‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c load!")
        except Exception as e:
            logging.error(f"L·ªói khi t·∫£i model: {str(e)}")
            raise

# Preload model khi kh·ªüi ƒë·ªông server (n·∫øu c√≥ th·ªÉ)
with app.app_context():
    try:
        load_model()
        logging.info("‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c preload!")
    except Exception as e:
        logging.error(f"L·ªói preload model: {str(e)}")

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/dashboard')
def dashboard():
    return render_template('dashboard.html')

@app.route('/predict', methods=['POST'])
def predict():
    try:
        # N·∫øu model kh√¥ng ƒë∆∞·ª£c preload th√†nh c√¥ng, th·ª≠ t·∫£i l·∫°i
        if model is None:
            load_model()
            
        if 'image' not in request.files:
            logging.warning("Kh√¥ng c√≥ file ·∫£nh ƒë∆∞·ª£c g·ª≠i!")
            return jsonify({'error': 'Kh√¥ng c√≥ file ·∫£nh ƒë∆∞·ª£c g·ª≠i!'}), 400

        file = request.files['image']
        if file.filename == '':
            return jsonify({'error': 'T√™n file r·ªóng!'}), 400

        image = Image.open(file).convert('RGB')
        image = image.resize((224, 224))
        img_array = np.array(image) / 255.0
        img_array = np.expand_dims(img_array, axis=0)

        predictions = model.predict(img_array)
        logging.info(f"üìä K·∫øt qu·∫£ d·ª± ƒëo√°n: {predictions}")
        return jsonify({'predictions': predictions.tolist()})
    except Exception as e:
        logging.error(f"L·ªói trong route /predict: {str(e)}")
        return jsonify({'error': f'Internal Server Error: {str(e)}'}), 500


# Mo hinh moi
app = Flask(__name__)
port = "5000"

urllib.request.urlretrieve("https://raw.githubusercontent.com/trongltgit/EMR-Analyzer/refs/heads/main/templates/dashboard.html", "/content/uploader.html")

@app.route("/")
def index():
    return Path('/content/uploader.html').read_text()

@app.route("/upload_file", methods=["POST"])
def upload_file():
    if 'file' not in request.files:
        return 'No file part'

    file = request.files['file']

    if file.filename == '':
        return 'No selected file'

    if file:
        image_path = '/content/' + file.filename
        file.save(image_path)  # Save the file to a folder named 'uploads'

        # ƒê·ªçc ·∫£nh v√† chuy·ªÉn v·ªÅ k√≠ch th∆∞·ªõc mong mu·ªën (240x240 trong tr∆∞·ªùng h·ª£p n√†y)
        image = cv2.imread(image_path)
        image = cv2.resize(image, (240, 240))
        image = np.expand_dims(image, axis=0)  # Th√™m chi·ªÅu batch

        # Chu·∫©n h√≥a d·ªØ li·ªáu (n·∫øu c·∫ßn)
        # image = image / 255.0

        # D·ª± ƒëo√°n nh√£n
        prediction = best_model.predict(image)
        binary_prediction = np.round(prediction)

        return json.dumps(binary_prediction.tolist())

    return 'Error uploading file'

# end mo hinh









if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
