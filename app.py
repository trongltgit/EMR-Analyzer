import os
import numpy as np
import tensorflow as tf
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
from PIL import Image
import gdown
import py7zr
import logging

logging.basicConfig(level=logging.DEBUG, filename="server.log",
                    format="%(asctime)s - %(levelname)s - %(message)s")

app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "*"}})  # Cho phÃ©p táº¥t cáº£ origins

# Config model
MODEL_FILE_ID = "1EpAgsWQSXi7CsUO8mEQDGAJyjdfN0T6n"  # ID file .keras trÃªn Google Drive
MODEL_FILE_NAME = "best_weights_model.keras"
MODEL_DIR = "./MyDrive/efficientnet/efficientnet"
MODEL_PATH = os.path.join(MODEL_DIR, MODEL_FILE_NAME)
SPLIT_FILES_DIR = "./models"  # ThÆ° má»¥c chá»©a cÃ¡c file nÃ©n .7z.001, .7z.002, ...

def download_model_from_drive():
    """Táº£i model tá»« Google Drive náº¿u chÆ°a cÃ³."""
    if not os.path.exists(MODEL_DIR):
        os.makedirs(MODEL_DIR, exist_ok=True)
    if not os.path.isfile(MODEL_PATH):
        logging.info("ðŸ§  Model chÆ°a tá»“n táº¡i, Ä‘ang táº£i tá»« Google Drive...")
        url = f"https://drive.google.com/uc?id={MODEL_FILE_ID}"
        gdown.download(url, MODEL_PATH, quiet=False)
        logging.info("âœ… Táº£i model tá»« Google Drive thÃ nh cÃ´ng!")

def assemble_model_from_split_files():
    """Ná»‘i cÃ¡c file nÃ©n .7z.001, .7z.002, ... thÃ nh file .keras."""
    if not os.path.exists(MODEL_DIR):
        os.makedirs(MODEL_DIR, exist_ok=True)
    if not os.path.isfile(MODEL_PATH):
        split_files = [os.path.join(SPLIT_FILES_DIR, f"best_weights_model.7z.{i:03d}") 
                       for i in range(1, 5)]  # Giáº£ sá»­ cÃ³ 4 file: .001, .002, .003, .004
        if all(os.path.isfile(f) for f in split_files):
            logging.info("ðŸ§  TÃ¬m tháº¥y cÃ¡c file nÃ©n, Ä‘ang giáº£i nÃ©n vÃ  ná»‘i...")
            archive_path = os.path.join(MODEL_DIR, "best_weights_model.7z")
            # Ná»‘i file thá»§ cÃ´ng
            with open(archive_path, 'wb') as outfile:
                for split_file in split_files:
                    with open(split_file, 'rb') as infile:
                        outfile.write(infile.read())
            # Giáº£i nÃ©n
            with py7zr.SevenZipFile(archive_path, mode='r') as archive:
                archive.extractall(path=MODEL_DIR)
            os.remove(archive_path)  # XÃ³a file nÃ©n táº¡m thá»i
            logging.info("âœ… ÄÃ£ ná»‘i vÃ  giáº£i nÃ©n model thÃ nh cÃ´ng!")
        else:
            logging.warning("KhÃ´ng tÃ¬m tháº¥y Ä‘á»§ cÃ¡c file nÃ©n trong thÆ° má»¥c models!")

def prepare_model():
    """Chuáº©n bá»‹ model: Æ°u tiÃªn ná»‘i file nÃ©n, náº¿u khÃ´ng thÃ¬ táº£i tá»« Drive."""
    if not os.path.isfile(MODEL_PATH):
        try:
            assemble_model_from_split_files()
        except Exception as e:
            logging.error(f"Lá»—i khi ná»‘i file nÃ©n: {e}")
            download_model_from_drive()

model = None
def load_model():
    global model
    if model is None:
        try:
            prepare_model()
            logging.info("ðŸ“¦ Äang load model vÃ o bá»™ nhá»›...")
            model = tf.keras.models.load_model(MODEL_PATH)
            logging.info("âœ… MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c load!")
        except Exception as e:
            logging.error(f"Lá»—i khi load model: {e}")
            raise

# Preload model khi khá»Ÿi Ä‘á»™ng server
with app.app_context():
    try:
        load_model()
        logging.info("âœ… MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c preload!")
    except Exception as e:
        logging.error(f"Lá»—i preload model: {e}")

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/dashboard')
def dashboard():
    return render_template('dashboard.html')

@app.route('/predict', methods=['POST'])
def predict():
   
  try:
        # Logic xá»­ lÃ½ yÃªu cáº§u
        return jsonify({'classification': 'result', 'score': 0.95})
    except Exception as e:
        return jsonify({'error': str(e)}), 500
  
  try:
        if model is None:
            load_model()

        if 'image' not in request.files:
            logging.warning("KhÃ´ng cÃ³ file áº£nh Ä‘Æ°á»£c gá»­i!")
            return jsonify({'error': 'KhÃ´ng cÃ³ file áº£nh Ä‘Æ°á»£c gá»­i!'}), 400

        file = request.files['image']
        if file.filename == '':
            return jsonify({'error': 'TÃªn file rá»—ng!'}), 400

        img = Image.open(file).convert('RGB').resize((224, 224))
        x = np.expand_dims(np.array(img) / 255.0, axis=0)

        preds = model.predict(x)[0][0]
        logging.info(f"ðŸ“Š Káº¿t quáº£ dá»± Ä‘oÃ¡n: {preds}")
        cls = 'Nodule' if preds > 0.5 else 'Non-Nodule'
        return jsonify({'classification': cls, 'score': float(preds)})
    except Exception as e:
        logging.error(f"Lá»—i trong route /predict: {e}")
        return jsonify({'error': f'Internal Server Error: {e}'}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=int(os.environ.get("PORT", 5000)))
