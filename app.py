import os
import shutil
import numpy as np
import tensorflow as tf
from flask import Flask, request, jsonify, render_template
from tensorflow.keras.models import load_model as keras_load_model
from flask_cors import CORS
from PIL import Image
import gdown
import logging
from retrying import retry
import py7zr

# Cáº¥u hÃ¬nh logging (ghi log vÃ o file server.log)
logging.basicConfig(level=logging.DEBUG, filename="server.log",
                    format="%(asctime)s - %(levelname)s - %(message)s")

app = Flask(__name__)
CORS(app)  # Cho phÃ©p táº¥t cáº£ origin

# Cáº¥u hÃ¬nh thÃ´ng sá»‘ cho model
MODEL_FILE_ID = "1EpAgsWQSXi7CsUO8mEQDGAJyjdfN0T6n"
MODEL_FILE_NAME = "best_weights_model.keras"
MODEL_DIR = "./MyDrive/efficientnet/efficientnet"
MODEL_PATH = os.path.join(MODEL_DIR, MODEL_FILE_NAME)
model = None

@retry(stop_max_attempt_number=3, wait_fixed=2000)
def download_model_gdown(url, output):
    gdown.download(url, output, quiet=False)

def assemble_model():
    """
    GhÃ©p cÃ¡c file .7z Ä‘Ã£ chia nhá» vÃ  giáº£i nÃ©n Ä‘á»ƒ láº¥y file model gá»‘c.
    """
    global model
    try:
        # Danh sÃ¡ch cÃ¡c file split trong thÆ° má»¥c models
        segments = [os.path.join(MODEL_DIR, f"best_weights_model.7z.00{i}") for i in range(1, 5)]
        logging.info("Kiá»ƒm tra sá»± tá»“n táº¡i cá»§a cÃ¡c file split: %s", segments)
        for seg in segments:
            if not os.path.exists(seg):
                logging.error("KhÃ´ng tÃ¬m tháº¥y file split: %s", seg)
                return
        # GhÃ©p cÃ¡c file split thÃ nh file archive hoÃ n chá»‰nh
        assembled_archive = os.path.join(MODEL_DIR, "best_weights_model.7z")
        with open(assembled_archive, 'wb') as outfile:
            for seg in segments:
                with open(seg, 'rb') as infile:
                    shutil.copyfileobj(infile, outfile)
        logging.info("GhÃ©p file .7z thÃ nh cÃ´ng. Báº¯t Ä‘áº§u giáº£i nÃ©n báº±ng py7zr...")

        # Giáº£i nÃ©n file archive báº±ng py7zr
        with py7zr.SevenZipFile(assembled_archive, mode='r') as archive:
            archive.extractall(path=MODEL_DIR)
        extracted_model = os.path.join(MODEL_DIR, MODEL_FILE_NAME)
        model = keras_load_model(extracted_model)
        logging.info("Model Ä‘Æ°á»£c load thÃ nh cÃ´ng tá»« file giáº£i nÃ©n!")
    except Exception as e:
        logging.error("Lá»—i khi ghÃ©p hoáº·c load model: %s", str(e))
        model = None

def download_model():
    """
    Táº£i model tá»« Google Drive náº¿u chÆ°a cÃ³. Náº¿u tháº¥t báº¡i, chuyá»ƒn sang ghÃ©p file .7z.
    """
    if not os.path.exists(MODEL_DIR):
        os.makedirs(MODEL_DIR, exist_ok=True)
    if not os.path.isfile(MODEL_PATH):
        try:
            logging.info("ðŸŒ Äang táº£i model tá»« Google Drive...")
            url = f"https://drive.google.com/uc?id={MODEL_FILE_ID}"
            download_model_gdown(url, MODEL_PATH)
            logging.info("âœ… Táº£i model tá»« Drive thÃ nh cÃ´ng!")
        except Exception as e:
            logging.warning("âš ï¸ KhÃ´ng táº£i Ä‘Æ°á»£c model tá»« Drive: %s", e)
            assemble_model()

def initialize_model():
    """
    Khá»Ÿi Ä‘á»™ng (load) model vÃ o bá»™ nhá»›.
    """
    global model
    if model is None:
        download_model()
        # Náº¿u cÃ³ file model cá»¥c bá»™ nhÆ°ng model chÆ°a Ä‘Æ°á»£c load, thá»­ load láº¡i
        if model is None and os.path.isfile(MODEL_PATH):
            try:
                logging.info("ðŸš€ Äang load model tá»« file cá»¥c bá»™...")
                model = keras_load_model(MODEL_PATH)
                logging.info("âœ… Model Ä‘Ã£ Ä‘Æ°á»£c load vÃ o bá»™ nhá»›!")
            except Exception as e:
                logging.error("Lá»—i khi load model cá»¥c bá»™: %s", e)

# Load model khi khá»Ÿi Ä‘á»™ng server
initialize_model()

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/dashboard')
def dashboard():
    return render_template('dashboard.html')

@app.route('/predict', methods=['POST'])
def predict():
    global model
    try:
        if model is None:
            initialize_model()
            if model is None:
                logging.error("Model khÃ´ng Ä‘Æ°á»£c load")
                return jsonify({'error': 'KhÃ´ng thá»ƒ táº£i model. Vui lÃ²ng thá»­ láº¡i sau.'}), 503

        if 'image' not in request.files:
            return jsonify({'error': 'KhÃ´ng cÃ³ file áº£nh trong request!'}), 400

        file = request.files['image']
        if file.filename == '':
            return jsonify({'error': 'TÃªn file áº£nh khÃ´ng há»£p lá»‡!'}), 400

        # Xá»­ lÃ½ áº£nh: chuyá»ƒn sang RGB vÃ  resize vá» 224x224
        img = Image.open(file).convert('RGB').resize((224, 224))
        x = np.expand_dims(np.array(img) / 255.0, axis=0)
        img.close()
        preds = model.predict(x)[0][0]
        cls = 'Nodule' if preds > 0.5 else 'Non-Nodule'
        return jsonify({'classification': cls, 'score': float(preds)})
    except Exception as e:
        logging.error("Lá»—i khi thá»±c hiá»‡n dá»± Ä‘oÃ¡n: %s", str(e), exc_info=True)
        return jsonify({'error': f'Lá»—i khi xá»­ lÃ½ áº£nh hoáº·c dá»± Ä‘oÃ¡n: {str(e)}'}), 500

if __name__ == '__main__':
    port = int(os.environ.get("PORT", 10000))
    app.run(host='0.0.0.0', port=port)
