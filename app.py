import os
from flask import Flask, render_template, request, redirect, url_for
import pandas as pd
from tensorflow.keras.models import load_model
from ydata_profiling import ProfileReport
from werkzeug.utils import secure_filename
import tensorflow as tf

app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 32 * 1024 * 1024  # Gi·ªõi h·∫°n upload file l√™n 32MB

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
UPLOAD_FOLDER = os.path.join(BASE_DIR, 'uploads')
STATIC_PROFILE_REPORTS = os.path.join(BASE_DIR, 'static', 'profile_reports')
MODELS_DIR = os.path.join(BASE_DIR, 'models')
MODEL_FILENAME = 'best_weights_model.keras'
MODEL_PATH = os.path.join(MODELS_DIR, MODEL_FILENAME)

os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(STATIC_PROFILE_REPORTS, exist_ok=True)
os.makedirs(MODELS_DIR, exist_ok=True)

model = None

def merge_model_parts():
    """Gh√©p c√°c ph·∫ßn .keras.001, .keras.002,... th√†nh file .keras"""
    part_files = sorted([
        f for f in os.listdir(MODELS_DIR)
        if f.startswith(MODEL_FILENAME + ".")
    ])
    if not part_files:
        print("‚ö†Ô∏è Kh√¥ng th·∫•y c√°c ph·∫ßn model.")
        return False
    print(f"üîß Gh√©p model t·ª´ c√°c ph·∫ßn: {part_files}")
    try:
        with open(MODEL_PATH, 'wb') as outfile:
            for part in part_files:
                with open(os.path.join(MODELS_DIR, part), 'rb') as pf:
                    while True:
                        chunk = pf.read(1024 * 1024)
                        if not chunk:
                            break
                        outfile.write(chunk)
        print(f"‚úÖ Gh√©p model th√†nh c√¥ng! ƒê√£ t·∫°o {MODEL_PATH} ({os.path.getsize(MODEL_PATH)} bytes)")
        return True
    except Exception as e:
        print(f"‚ùå L·ªói khi gh√©p model: {e}")
        return False

def try_load_model():
    """T·∫£i m√¥ h√¨nh v·ªõi ki·ªÉm tra l·ªói chi ti·∫øt"""
    global model
    try:
        print(f"üîç Ki·ªÉm tra model ·ªü: {MODEL_PATH}")
        if not os.path.exists(MODEL_PATH):
            print("üîç File model ch∆∞a t·ªìn t·∫°i, th·ª≠ merge...")
            merged = merge_model_parts()
            if not merged:
                print("‚ö†Ô∏è Model ch∆∞a ƒë∆∞·ª£c gh√©p.")
        
        if os.path.exists(MODEL_PATH):
            if not os.access(MODEL_PATH, os.R_OK):
                print(f"‚ö†Ô∏è Kh√¥ng c√≥ quy·ªÅn truy c·∫≠p v√†o {MODEL_PATH}. Ki·ªÉm tra l·∫°i!")
                return
            
            print("üîç ƒêang load model...")
            model = load_model(MODEL_PATH)
            print("‚úÖ Model ƒë√£ ƒë∆∞·ª£c load.")
        else:
            print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file model sau khi merge.")
            model = None
    except Exception as e:
        print(f"‚ùå L·ªói khi load model: {e}")
        model = None

try_load_model()



# C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt
!pip install ydata-profiling
!pip install gdown

import pandas as pd
import os
import gdown
from ydata_profiling import ProfileReport
from sklearn.model_selection import train_test_split

# File ID t·ª´ Google Drive (thay b·∫±ng ID th·ª±c t·∫ø)
file_id = '1t_VjKggCbXBYwJowLbC898WKsFuxiNG9'  # Thay b·∫±ng ID th·ª±c t·∫ø
output_file = 'healthcare_dataset.csv'

# URL ƒë·ªÉ t·∫£i file t·ª´ Google Drive
gdown.download(f'https://drive.google.com/uc?id={file_id}', output_file, quiet=False)

# Ki·ªÉm tra n·∫øu file ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng
if not os.path.exists(output_file):
    print(f"Error: File not found at {output_file}")
else:
    data = pd.read_csv(output_file)

    # T·∫°o b√°o c√°o
    profile = ProfileReport(data, title='Pandas Profiling Report Dummy')

    # Xu·∫•t b√°o c√°o ra file
    profile.to_file(output_file="report_dummy.html")
    profile.to_file(output_file="report_dummy.json")

    # T√°ch t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm th·ª≠
    X_train, X_test = train_test_split(data, test_size=0.2, random_state=0)

    # Hi·ªÉn th·ªã b√°o c√°o (ch·ªâ trong notebook)

profile






# File ID t·ª´ Google Drive (thay b·∫±ng ID th·ª±c t·∫ø)
file_id = '1EpAgsWQSXi7CsUO8mEQDGAJyjdfN0T6n'  # Thay b·∫±ng ID th·ª±c t·∫ø
output_file = 'best_weights_model.keras'

# URL ƒë·ªÉ t·∫£i file t·ª´ Google Drive
gdown.download(f'https://drive.google.com/uc?id={file_id}', output_file, quiet=False)

# Ki·ªÉm tra n·∫øu file ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng
if not os.path.exists(output_file):
    print(f"Error: File not found at {output_file}")
else:
   from tensorflow import keras

model = keras.models.load_model("best_weights_model.keras")







@app.route('/')
def home():
    return render_template('index.html')

@app.route('/dashboard')
def dashboard():
    return render_template('dashboard.html')

@app.route("/check-model")
def check_model():
    """Ki·ªÉm tra s·ª± t·ªìn t·∫°i c·ªßa file model"""
    if os.path.exists(MODEL_PATH):
        return "‚úÖ File t·ªìn t·∫°i!"
    else:
        return "‚ùå Kh√¥ng t√¨m th·∫•y file!"

@app.route('/emr_profile.html', methods=['GET', 'POST'])
def emr_profile():
    """X·ª≠ l√Ω t·∫£i file v√† t·∫°o b√°o c√°o h·ªì s∆° EMR"""
    error = None
    if request.method == 'POST':
        file = request.files.get('file')
        if not file:
            return render_template("emr_profile.html", error="Vui l√≤ng ch·ªçn file.")

        filename = secure_filename(file.filename)
        filepath = os.path.join(UPLOAD_FOLDER, filename)
        file.save(filepath)

        try:
            if filename.lower().endswith('.csv'):
                df = pd.read_csv(filepath)
            elif filename.lower().endswith(('.xls', '.xlsx')):
                df = pd.read_excel(filepath)
            else:
                return render_template("emr_profile.html", error="File kh√¥ng h·ª£p l·ªá (ch·ªâ nh·∫≠n .csv, .xls, .xlsx).")

            if df.shape[0] > 100_000 or df.shape[1] > 100:
                error = "File qu√° l·ªõn (h∆°n 100.000 d√≤ng ho·∫∑c 100 c·ªôt), kh√¥ng th·ªÉ sinh b√°o c√°o profile."
                return render_template("emr_profile.html", error=error)

            try:
                profile = ProfileReport(df, title="EMR Report", minimal=True)
                report_path = os.path.join(STATIC_PROFILE_REPORTS, 'report.html')
                profile.to_file(report_path)
                return redirect(url_for('static', filename='profile_reports/report.html'))
            except MemoryError:
                error = "File qu√° l·ªõn, kh√¥ng th·ªÉ sinh b√°o c√°o profile (thi·∫øu b·ªô nh·ªõ RAM server)."
            except Exception as e:
                error = f"L·ªói khi sinh b√°o c√°o: {e}"
        except Exception as e:
            error = f"L·ªói khi ph√¢n t√≠ch: {e}"

        return render_template("emr_profile.html", error=error)

    return render_template("emr_profile.html", error=error)

@app.route('/emr_prediction.html', methods=['GET', 'POST'])
def emr_prediction():
    """X·ª≠ l√Ω d·ª± ƒëo√°n t·ª´ ·∫£nh h·ªì s∆° EMR"""
    prediction = None
    error = None

    if request.method == 'POST':
        file = request.files.get('file')
        if not file:
            error = "Vui l√≤ng ch·ªçn ·∫£nh."
            return render_template("emr_prediction.html", prediction=prediction, error=error)

        global model
        if model is None:
            try_load_model()
        if model is None:
            error = (
                f"Model ch∆∞a ƒë∆∞·ª£c t·∫£i ho·∫∑c kh√¥ng t·ªìn t·∫°i tr√™n server ({MODEL_PATH}).<br>"
                "H√£y ki·ªÉm tra l·∫°i log server, ƒë·∫£m b·∫£o ƒë√£ upload ƒë·ªß c√°c ph·∫ßn .keras.001, .keras.002,... v√†o th∆∞ m·ª•c <b>models</b>!"
            )
            return render_template("emr_prediction.html", prediction=prediction, error=error)

        filename = secure_filename(file.filename)
        filepath = os.path.join(UPLOAD_FOLDER, filename)
        file.save(filepath)

        try:
            img = tf.keras.preprocessing.image.load_img(filepath, target_size=(224, 224))
            img_array = tf.keras.preprocessing.image.img_to_array(img)
            img_array = tf.expand_dims(img_array, axis=0) / 255.0
            pred = model.predict(img_array)
            prediction = "Nodule" if pred[0][0] > 0.5 else "Non-Nodule"
        except Exception as e:
            error = f"L·ªói khi d·ª± ƒëo√°n: {e}"

    return render_template("emr_prediction.html", prediction=prediction, error=error)

if __name__ == '__main__':
    app.run(debug=False, host='0.0.0.0', port=int(os.environ.get("PORT", 5000)))
